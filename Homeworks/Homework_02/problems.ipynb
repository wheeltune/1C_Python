{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соберем датасет из данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame(columns=['text', 'lang'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"2.tmp\", \"r\") as file:\n",
    "    file_content = file.read()\n",
    "    file_content = re.sub('\\n\\x00+', '', file_content)\n",
    "    paragraphs = file_content.split(\"\\n\")\n",
    "\n",
    "    paragraphs = list(filter(lambda p: len(p) > 0, paragraphs))\n",
    "    \n",
    "    chinese_dataset = pd.DataFrame({'lang': ['ch'] * len(paragraphs),\n",
    "                                    'text': paragraphs})\n",
    "    \n",
    "    dataset = pd.concat([dataset, chinese_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"3.tmp\", \"r\") as file:\n",
    "    file_content = file.read()\n",
    "    file_content = re.sub('\\x00', '', file_content)\n",
    "    file_content = re.sub('\\n\\s+\\n', '\\n\\n', file_content)\n",
    "    file_content = re.sub('\\n[^\\n]', '', file_content)\n",
    "    file_content = re.sub('\\n\\n', '\\n', file_content)\n",
    "    paragraphs = file_content.split(\"\\n\")\n",
    "    \n",
    "    paragraphs = list(filter(lambda p: len(p) > 0, paragraphs))\n",
    "    \n",
    "    english_dataset = pd.DataFrame({'lang': ['en'] * len(paragraphs),\n",
    "                                    'text': paragraphs})\n",
    "    \n",
    "    dataset = pd.concat([dataset, english_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"4.tmp\", \"r\") as file:\n",
    "    file_content = file.read()\n",
    "    file_content = re.sub('\\n\\x00+', '', file_content)\n",
    "    paragraphs = file_content.split(\"\\n\")\n",
    "    \n",
    "    paragraphs = list(filter(lambda p: len(p) > 0, paragraphs))\n",
    "\n",
    "    japanese_dataset = pd.DataFrame({'lang': ['ja'] * len(paragraphs),\n",
    "                                    'text': paragraphs})\n",
    "    \n",
    "    dataset = pd.concat([dataset, japanese_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier:\n",
    "    def __init__(self, langs):\n",
    "        self.langs = list(map(lambda lang: {'name': lang[0], 'ord': int(lang[1])}, langs))\n",
    "    \n",
    "    def detect(self, text):    \n",
    "        text_ord = list(filter(lambda s: ord(s) > 64, list(text)))\n",
    "        text_ord = np.median(list(map(ord, text_ord)))\n",
    "        lang_index = np.argmin(list(map(lambda lang: np.abs(lang['ord'] - text_ord), self.langs)))\n",
    "        return self.langs[lang_index]['name']\n",
    "    \n",
    "    def classify(self, data):\n",
    "        return list(map(self.detect, data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Classifier([('en', 5000), ('ja', 15000), ('ch', 25000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = classifier.classify(dataset['text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Accuracy score: 1.0'"
      ]
     },
     "execution_count": 866,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Accuracy score: \" + str(sum(dataset['lang'].values == y_predict) / len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не имеет смысла запускать `KFold` поскольку все классифицируется верно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Base64:    \n",
    "    def encode(to_encode):\n",
    "        symbols = np.array(\n",
    "            bytearray(map(ord, \n",
    "                          list(\"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/\")))\n",
    "        )\n",
    "        \n",
    "        to_encode = bytearray(to_encode)\n",
    "        \n",
    "        added = 0\n",
    "        while len(to_encode) % 3 != 0:\n",
    "            to_encode.append(0)\n",
    "            added += 1\n",
    "        \n",
    "        grouped = np.array(to_encode).reshape((int(len(to_encode) / 3), 3))\n",
    "        \n",
    "        encode_group = lambda group: [((group[0] & 252) >> 2),\n",
    "                                      ((group[0] & 3)  << 4) + ((group[1] & 240) >> 4),\n",
    "                                      ((group[1] & 15) << 2) + ((group[2] & 192) >> 6),\n",
    "                                      ((group[2] & 63)) ]\n",
    "        \n",
    "        regrouped = np.array(list(map(encode_group, grouped)))\n",
    "        encoded = bytearray(symbols[regrouped.flatten()])\n",
    "        \n",
    "        for i in range(1, added + 1):\n",
    "            encoded[-i] = ord('=')\n",
    "        \n",
    "        return bytes(encoded)\n",
    "        \n",
    "    def decode(to_decode):\n",
    "        symbols = bytearray(map(ord, \n",
    "                          list(\"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/\")))\n",
    "        \n",
    "        \n",
    "        to_decode = bytearray(to_decode)\n",
    "        added = 0\n",
    "        while to_decode[-(added + 1)] == ord('='):\n",
    "            added += 1\n",
    "            to_decode[-added] = symbols[0]\n",
    "        \n",
    "        to_decode = list(map(symbols.index, to_decode))\n",
    "        grouped = np.array(to_decode).reshape((int(len(to_decode) / 4), 4))\n",
    "        \n",
    "        decode_group = lambda group: [((group[0]       << 2) + ((group[1] & 48) >> 4)),\n",
    "                                      ((group[1] & 15) << 4) + ((group[2] & 60) >> 2),\n",
    "                                      ((group[2] & 3)  << 6) + ((group[3]))]\n",
    "        \n",
    "        regrouped = np.array(list(map(decode_group, grouped)))\n",
    "        if added > 0:\n",
    "            return bytes(list(regrouped.flatten()[:-added]))\n",
    "        else:\n",
    "            return bytes(list(regrouped.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 869,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**5 + 2**4 + 2**3 + 2**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My base64:\n",
      "b'44Gj44Gm6KiA44Gj44Gf77ya44CM44GT44GTIOODm+ODg+ODk+ODg+ODiOOBruS4reOBruWuneefs+OBp+OBme+8gSAn77yD44OU44OU44Kk44Oz44Gv44GX44Gw44KJ44GP44GX44Gm55yg44KK44Gr6JC944Gh44CB5pyo44CF44Gu5LiL44Gu5YiI44KK6Iqd55Sf44Gr5oyB44Gh5LiK44GS44KJ44KM44Gm6YGL44Gw44KM44Gf44CC44Gd44GT44Gn5b2844Gv5p+U44KJ44GL44GE44OZ44OD44OJ44Gu5LiK44Gr572u44GL44KM44CB5aSc44Gu5q6L44KK44Gu6YOo5YiG44KS55yg44Gj44Gf44CC44K144Og44Gv5b28'\n",
      "\n",
      "base64:\n",
      "b'44Gj44Gm6KiA44Gj44Gf77ya44CM44GT44GTIOODm+ODg+ODk+ODg+ODiOOBruS4reOBruWuneefs+OBp+OBme+8gSAn77yD44OU44OU44Kk44Oz44Gv44GX44Gw44KJ44GP44GX44Gm55yg44KK44Gr6JC944Gh44CB5pyo44CF44Gu5LiL44Gu5YiI44KK6Iqd55Sf44Gr5oyB44Gh5LiK44GS44KJ44KM44Gm6YGL44Gw44KM44Gf44CC44Gd44GT44Gn5b2844Gv5p+U44KJ44GL44GE44OZ44OD44OJ44Gu5LiK44Gr572u44GL44KM44CB5aSc44Gu5q6L44KK44Gu6YOo5YiG44KS55yg44Gj44Gf44CC44K144Og44Gv5b28'\n",
      "\n",
      "My base64:\n",
      "b'44GR44KL44Gf44KB44Gr5pyo44CF44KS55m744Gj44Gf44CC44Gd44KM44Gv6Iul6ICF44KS6KaL44Gk44GR44KL44Gf44KB44Gr56m044Gr5b+N44Gz6L6844KT44Gg44CC44Gd44KM44Gv56qT44KS6YCa44Gj44Gm5Y+X44GR5Y+w44KS6KaL44Gk44GR44Gf44CC'\n",
      "\n",
      "base64:\n",
      "b'44GR44KL44Gf44KB44Gr5pyo44CF44KS55m744Gj44Gf44CC44Gd44KM44Gv6Iul6ICF44KS6KaL44Gk44GR44KL44Gf44KB44Gr56m044Gr5b+N44Gz6L6844KT44Gg44CC44Gd44KM44Gv56qT44KS6YCa44Gj44Gm5Y+X44GR5Y+w44KS6KaL44Gk44GR44Gf44CC'\n",
      "\n",
      "My base64:\n",
      "b'SW4gdGhpcyBmYXIgbGFuZCBiZW5lYXRoIGhlIHRyZWVzLA=='\n",
      "\n",
      "base64:\n",
      "b'SW4gdGhpcyBmYXIgbGFuZCBiZW5lYXRoIGhlIHRyZWVzLA=='\n",
      "\n",
      "My base64:\n",
      "b'4oCYRGVzZXJ2ZXMgaXQhIEkgZGFyZXNheWhlIGRvZXMuIE1hbnkgdGhhdCBsaXZlIGRlc2VydmUgZGVhdGguIEFuZCBzb21lIHRhdCBkaWUgZGVzZXJ2ZSBsaWZlLiBDYW4geW91IGdpdmUgaXQgdG8gdGhlbT8gVGhlIGRvIG5vdCBiZSB0b28gZWFnZXIgdG8gZGVhbCBvdXQgZGVhdGggaW4ganVkZ2VtZXQuIEZvciBldmVuIHRoZSB2ZXJ5IHdpc2UgY2Fubm90IHNlZSBhbGwgZW5kcy4gSSBhdmUgbm90IG11Y2ggaG9wZSB0aGF0IEdvbGx1bSBjYW4gYmUgY3VyZWQgYmVmb3JlaGUgZGllcywgYnV0IHRoZXJlIGlzIGEgY2hhbmNlIG9mIGl0LiBBbmQgaGUgaXMgYnVuZCB1cCB3aXRoIHRoZSBmYXRlIG9mIHRoZSBSaW5nLiBNeSBoZWFydCB0ZWxscyBlIHRoYXQgaGUgaGFzIHNvbWUgcGFydCB0byBwbGF5IHlldCwgZm9yIGdvb2Qgb3IgbGwsIGJlZm9yZSB0aGUgZW5kOyBhbmQgd2hlbiB0aGF0IGNvbWVzLCB0aGUgcGl0eW9mIEJpbGJvIG1heSBydWxlIHRoZSBmYXRlIG9mIG1hbnkg4oCTIHlvdXJzIG5vdCBsZXN0LiBJbiBhbnkgY2FzZSB3ZSBkaWQgbm90IGtpbGwgaGltOiBoZSBpcyB2ZXJ5IG9kIGFuZCB2ZXJ5IHdyZXRjaGVkLiBUaGUgV29vZC1lbHZlcyBoYXZlIGhpbSBpbiBwaXNvbiwgYnV0IHRoZXkgdHJlYXQgaGltIHdpdGggc3VjaCBraW5kbmVzcyBhcyB0aHkgY2FuIGZpbmQgaW4gdGhlaXIgd2lzZSBoZWFydHMu4oCZ'\n",
      "\n",
      "base64:\n",
      "b'4oCYRGVzZXJ2ZXMgaXQhIEkgZGFyZXNheWhlIGRvZXMuIE1hbnkgdGhhdCBsaXZlIGRlc2VydmUgZGVhdGguIEFuZCBzb21lIHRhdCBkaWUgZGVzZXJ2ZSBsaWZlLiBDYW4geW91IGdpdmUgaXQgdG8gdGhlbT8gVGhlIGRvIG5vdCBiZSB0b28gZWFnZXIgdG8gZGVhbCBvdXQgZGVhdGggaW4ganVkZ2VtZXQuIEZvciBldmVuIHRoZSB2ZXJ5IHdpc2UgY2Fubm90IHNlZSBhbGwgZW5kcy4gSSBhdmUgbm90IG11Y2ggaG9wZSB0aGF0IEdvbGx1bSBjYW4gYmUgY3VyZWQgYmVmb3JlaGUgZGllcywgYnV0IHRoZXJlIGlzIGEgY2hhbmNlIG9mIGl0LiBBbmQgaGUgaXMgYnVuZCB1cCB3aXRoIHRoZSBmYXRlIG9mIHRoZSBSaW5nLiBNeSBoZWFydCB0ZWxscyBlIHRoYXQgaGUgaGFzIHNvbWUgcGFydCB0byBwbGF5IHlldCwgZm9yIGdvb2Qgb3IgbGwsIGJlZm9yZSB0aGUgZW5kOyBhbmQgd2hlbiB0aGF0IGNvbWVzLCB0aGUgcGl0eW9mIEJpbGJvIG1heSBydWxlIHRoZSBmYXRlIG9mIG1hbnkg4oCTIHlvdXJzIG5vdCBsZXN0LiBJbiBhbnkgY2FzZSB3ZSBkaWQgbm90IGtpbGwgaGltOiBoZSBpcyB2ZXJ5IG9kIGFuZCB2ZXJ5IHdyZXRjaGVkLiBUaGUgV29vZC1lbHZlcyBoYXZlIGhpbSBpbiBwaXNvbiwgYnV0IHRoZXkgdHJlYXQgaGltIHdpdGggc3VjaCBraW5kbmVzcyBhcyB0aHkgY2FuIGZpbmQgaW4gdGhlaXIgd2lzZSBoZWFydHMu4oCZ'\n",
      "\n",
      "My base64:\n",
      "b'5Zyo54eD54eS6JGX44CC57K+6Z2I5YCR5Z2Q5Zyo6I2J5Zyw5LiK5oiW5Zyo6ICB5qi55bm56Yu45LiK55qE54Gr5LiK44CC5pyJ5Lqb5Lq65L6G6YGO5p2v5a2Q77yM5YCS5p2v6aOy5paZO+WFtuS7luS6uuaKiumjn+eJqeaUvuWcqOWghuepjeeahOebpOWtkOWSjOebpOWtkOS4iuOAgiDvvIPvvIPvvIPvvIPvvIPvvIPigJzpgJnmmK/kuI3lpb3nmoTou4rosrvvvIzigJ3ku5blgJHlsI3mpa3ppJjmhJvlpb3ogIXoqqrvvIwg4oCc5Zug54K65oiR5YCR5L2P5Zyo6YGg6Zui5oiR5YCR5aSn5buz55qE57ag5qi55p6X6KOh44CC5aaC5p6c5L2g5piv5oiR5YCR5Zyo5a6255qE5a6i5Lq677yM5oiR5YCR5pyD5pu05aW95Zyw5bCN5b6F5L2g44CC4oCc77yD77yD4oCd5oiR5Ly85LmO5bCN55Sf5pel6IGa5pyD5L6G6Kqq6Laz5aSg5aW977yM4oCc5byX5rSb5aSa6Kqq44CCIO+8g++8g+earuearuW+jOS+huWbnuaDs+i1t+mjn+eJqeaIlumjsuaWmeeahOS4gOm7nu+8jOWboOeCuuS7lueahOmgreiFpuWFhea7v+S6huWwj+eyvumdiOiHieS4iueahOWFieiKku+8jOiBsumfs+eahOiBsumfs+WmguatpOWkmuaoo++8jOe+jum6l++8jOiuk+S7lg=='\n",
      "\n",
      "base64:\n",
      "b'5Zyo54eD54eS6JGX44CC57K+6Z2I5YCR5Z2Q5Zyo6I2J5Zyw5LiK5oiW5Zyo6ICB5qi55bm56Yu45LiK55qE54Gr5LiK44CC5pyJ5Lqb5Lq65L6G6YGO5p2v5a2Q77yM5YCS5p2v6aOy5paZO+WFtuS7luS6uuaKiumjn+eJqeaUvuWcqOWghuepjeeahOebpOWtkOWSjOebpOWtkOS4iuOAgiDvvIPvvIPvvIPvvIPvvIPvvIPigJzpgJnmmK/kuI3lpb3nmoTou4rosrvvvIzigJ3ku5blgJHlsI3mpa3ppJjmhJvlpb3ogIXoqqrvvIwg4oCc5Zug54K65oiR5YCR5L2P5Zyo6YGg6Zui5oiR5YCR5aSn5buz55qE57ag5qi55p6X6KOh44CC5aaC5p6c5L2g5piv5oiR5YCR5Zyo5a6255qE5a6i5Lq677yM5oiR5YCR5pyD5pu05aW95Zyw5bCN5b6F5L2g44CC4oCc77yD77yD4oCd5oiR5Ly85LmO5bCN55Sf5pel6IGa5pyD5L6G6Kqq6Laz5aSg5aW977yM4oCc5byX5rSb5aSa6Kqq44CCIO+8g++8g+earuearuW+jOS+huWbnuaDs+i1t+mjn+eJqeaIlumjsuaWmeeahOS4gOm7nu+8jOWboOeCuuS7lueahOmgreiFpuWFhea7v+S6huWwj+eyvumdiOiHieS4iueahOWFieiKku+8jOiBsumfs+eahOiBsumfs+WmguatpOWkmuaoo++8jOe+jum6l++8jOiuk+S7lg=='\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in np.random.randint(len(dataset), size=5):\n",
    "    b = bytes(dataset.iloc[i]['text'], 'utf-8')\n",
    "    print(\"My base64:\", Base64.encode(b), sep=\"\\n\", end=\"\\n\\n\")\n",
    "    print(\"base64:\", base64.b64encode(b), sep=\"\\n\", end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []\n",
    "for i in range(len(dataset)):\n",
    "    b = bytes(dataset.iloc[i]['text'], 'utf-8')\n",
    "    test.append(Base64.encode(b) == base64.b64encode(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'100.0% - is correct'"
      ]
     },
     "execution_count": 872,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(len(test) / sum(test) * 100) + \"% - is correct\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decode testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode:\n",
      "他們盡可能快地跋涉，穿過草坪，穿過厚厚的老樹葉;所有關於他們的雨水滴流淌。他們沒有說話，但是一直在回想起來，從一邊到另一邊。 ＃＃半小時後，皮皮說：“我希望我們沒有向南轉，太過不了長長的木頭！這不是一個非常寬闊的腰帶 - 我應該在最廣泛的地方說出一英里以上 - 我們現在應該通過它了。“＃＃”我們開始走在曲折上是不好的，“弗羅多說。 “這不會改善事情。讓我們繼續保持原樣！我不知道我是否想進入公開場合。“＃他們還有幾英里的路程。然後，太陽再次閃閃發光，雨水減弱。現在已經過了中午，他們覺得是午餐的時候\n",
      "\n",
      "Original:\n",
      "他們盡可能快地跋涉，穿過草坪，穿過厚厚的老樹葉;所有關於他們的雨水滴流淌。他們沒有說話，但是一直在回想起來，從一邊到另一邊。 ＃＃半小時後，皮皮說：“我希望我們沒有向南轉，太過不了長長的木頭！這不是一個非常寬闊的腰帶 - 我應該在最廣泛的地方說出一英里以上 - 我們現在應該通過它了。“＃＃”我們開始走在曲折上是不好的，“弗羅多說。 “這不會改善事情。讓我們繼續保持原樣！我不知道我是否想進入公開場合。“＃他們還有幾英里的路程。然後，太陽再次閃閃發光，雨水減弱。現在已經過了中午，他們覺得是午餐的時候\n",
      "\n",
      "Decode:\n",
      "しょう。しかし、現時点では、この事があなたにどのように来たのかを知る必要があり、それが十分に物語にな\n",
      "\n",
      "Original:\n",
      "しょう。しかし、現時点では、この事があなたにどのように来たのかを知る必要があり、それが十分に物語にな\n",
      "\n",
      "Decode:\n",
      "ンスがあれば、いつか、戻ってくるだろう。あなたが来たら歓迎するよ。しかし、今私は考えがある。それはす\n",
      "\n",
      "Original:\n",
      "ンスがあれば、いつか、戻ってくるだろう。あなたが来たら歓迎するよ。しかし、今私は考えがある。それはす\n",
      "\n",
      "Decode:\n",
      "‘Mr. Frodo, sir!’ cried am quaking. ‘Don’t let him hurt me, sir! Don’t le him turn me into anything unnatural! My old dad ould take on so. I meant no harm, on my honour, sr!’\n",
      "\n",
      "Original:\n",
      "‘Mr. Frodo, sir!’ cried am quaking. ‘Don’t let him hurt me, sir! Don’t le him turn me into anything unnatural! My old dad ould take on so. I meant no harm, on my honour, sr!’\n",
      "\n",
      "Decode:\n",
      "At the bottom of the Hill on its western sidethey came to the gate opening on to a narrow lane There they halted and adjusted the straps of ther packs. Presently Sam appeared, trotting quicklyand breathing hard; his heavy pack was hoisted hih on his shoulders, and he had put on his head a all shapeless fell bag, which he called a hat. Inthe gloom he looked very much like a dwarf.\n",
      "\n",
      "Original:\n",
      "At the bottom of the Hill on its western sidethey came to the gate opening on to a narrow lane There they halted and adjusted the straps of ther packs. Presently Sam appeared, trotting quicklyand breathing hard; his heavy pack was hoisted hih on his shoulders, and he had put on his head a all shapeless fell bag, which he called a hat. Inthe gloom he looked very much like a dwarf.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in np.random.randint(len(dataset), size=5):\n",
    "    b = bytes(dataset.iloc[i]['text'], 'utf-8')\n",
    "    print(\"Decode:\", Base64.decode(Base64.encode(b)).decode('utf-8'), sep=\"\\n\", end=\"\\n\\n\")\n",
    "    print(\"Original:\", dataset.iloc[i]['text'], sep=\"\\n\", end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []\n",
    "for i in range(len(dataset)):\n",
    "    b = bytes(dataset.iloc[i]['text'], 'utf-8')\n",
    "    test.append(Base64.decode(Base64.encode(b)) == b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'100.0% - is correct'"
      ]
     },
     "execution_count": 875,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(len(test) / sum(test) * 100) + \"% - is correct\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
