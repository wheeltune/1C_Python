{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 1\n",
    "\n",
    "\n",
    "### Целью этого задания является знакомство со стандартными контейнерами и некторыми функциями из стандартных библиотек для машинного обучения.\n",
    "\n",
    "Напишите наивный байесовский классификатор и сравните его с реализацией NaiveBayesClassifier из библиотеки nltk.\n",
    "\n",
    "Написанный вами классификатор должен обладать следубщими свойствами:\n",
    "<ul>\n",
    "<li>В предложенном интерфейсе класса должны быть реализованы все методы и все поля. Для их хранения предподсчитанных данных рекомендуется использовать контейнеры Counter или defaultdict из библиотеки collections. Для предсказания категории рекомендуется использовать numpy.</li>\n",
    "<li>Должна использоваться модель, предложенная в теории.</li>\n",
    "<li>Точность предсказаний не менее <b>0.9</b>!</li>\n",
    "<li>После реализации класса протестируйте его с помощью кроссвалидации с k=10. Рекомендуется использовать класс KFold из библиотеки sklearn.</li>\n",
    "<li>Постройте постройте диаграмму размаха для классификаторов (своего и из библиотеки).</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Теория"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теория находится в файле problems1-theory.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Решение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk import NaiveBayesClassifier\n",
    "from nltk.tokenize import word_tokenize\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Прочитайте данные из файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"ham-spam.csv\"\n",
    "data_frame = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>msg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject : re : 2 . 882 s - &gt; np np &gt; date : su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject : s - &gt; np + np the discussion of s - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject : 2 . 882 s - &gt; np np . . . for me it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject : gent conference \" for the listserv \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject : query : causatives in korean could a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                                msg\n",
       "0    ham  Subject : re : 2 . 882 s - > np np > date : su...\n",
       "1    ham  Subject : s - > np + np the discussion of s - ...\n",
       "2    ham  Subject : 2 . 882 s - > np np . . . for me it ...\n",
       "3    ham  Subject : gent conference \" for the listserv \"...\n",
       "4    ham  Subject : query : causatives in korean could a..."
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = np.array(data_frame[\"msg\"]), np.array(data_frame[\"target\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Реализуйте все методы в классе NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes(object):\n",
    "    \"\"\"\n",
    "    Наивный байесовский классификатор.\n",
    "    Для каждого входного сообщения слово учитывается один раз при расчете итоговой вероятности.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    category_priors : default | None, optional, default None\n",
    "        Априорные вероятности категорий.\n",
    "        Если None, то классификатор должен сам их вычислить.\n",
    "\n",
    "    weight : float, optional, default 1\n",
    "        Вес одного слова в формуле взвешенной вероятности\n",
    "\n",
    "    supposed_prob : float, optional, default 0.5\n",
    "        Предполагаемая вероятность слова в категории\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, category_priors=None, weight=1, supposed_prob=0.5):\n",
    "        self.category_priors = category_priors\n",
    "        self.weight = weight\n",
    "        self.supposed_prob = supposed_prob\n",
    "\n",
    "        # Количество отдельных слов в заданной категории\n",
    "        self.feature_category_counts = defaultdict(Counter)\n",
    "        self.feature_category_count = defaultdict(int)\n",
    "\n",
    "        # Количество всех документов в данной категории\n",
    "        self.category_doc_counts = Counter()\n",
    "\n",
    "        # Количество встреч слова во всех сообщениях\n",
    "        self.feature_counts = Counter()\n",
    "        self.feature_count = 0\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        \"\"\"\n",
    "        Производит обучение наивного байесовского классификатора.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x_train : list of str\n",
    "            содержит список (сообщений). слова в сообщении должны быть разделены пробелом.\n",
    "\n",
    "        y_train : list of str\n",
    "            содержит список меток (названий категорий) для сообщений из x_train\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns self\n",
    "        \"\"\"\n",
    "        # Подсчитываем количество категорий, документов и слов в каждой категории\n",
    "        # и количество встреч слова во всех сообщениях\n",
    "        self.category_doc_counts.update(y_train)\n",
    "        \n",
    "        x_train = np.array(list(\n",
    "            map(lambda message: np.unique(message.split()), x_train)))\n",
    "        \n",
    "        for (document, cat) in zip(x_train, y_train):\n",
    "            self.feature_category_counts[cat].update(document)\n",
    "            self.feature_category_count[cat] = \\\n",
    "                sum(list(self.feature_category_counts[cat].values()))\n",
    "            self.feature_counts.update(document)\n",
    "        self.feature_count = sum(list(self.feature_counts.values()))\n",
    "        \n",
    "        # Если априорные вероятности категорий не заданы, то надо аппроксимировать их\n",
    "        if self.category_priors is None:\n",
    "            y_train = np.array(y_train)\n",
    "            \n",
    "            self.category_priors = defaultdict(float)\n",
    "            for cat in self.get_categories():\n",
    "                self.category_priors[cat] = sum(y_train == cat) / len(y_train)\n",
    "            \n",
    "        return self\n",
    "\n",
    "    def predict(self, text):\n",
    "        \"\"\"\n",
    "        Предсказывает метки категорий для text.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text : list of list of str | list of str | str\n",
    "            Входной текст описывается строкой, которая будет токенизирована по пробелу.\n",
    "            Если строка не токенизирована, то текст должен быть токенизирован.\n",
    "            Может быть передано несколько сообщений, которые будут токенезированы, если необходимо.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        categories : list of str\n",
    "            Возвращает названия категорий для text.\n",
    "        \"\"\"\n",
    "        texts = self.tokenize(text)\n",
    "        \n",
    "        categories = []\n",
    "        for text in texts:\n",
    "            categories.append(\n",
    "                self.get_categories()[np.argmax(self.get_probs(text))])\n",
    "\n",
    "        return categories\n",
    "\n",
    "    def score(self, text, labels):\n",
    "        \"\"\"\n",
    "        Возвращает точность предсказаний на text для правильных категорий labels.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text : list of list of str | list of str | str\n",
    "            Входной текст описывается строкой, которая будет токенизирована по пробелу.\n",
    "            Если строка не токенизирована, то текст должен быть токенизирован.\n",
    "            Может быть передано несколько сообщений, которые будут токенезированы, если необходимо.\n",
    "        labels : list of str\n",
    "            Список категорий для каждого токена из text.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        acc : list of float\n",
    "            Массив с точностями предсказаний точность предсказания.\n",
    "        \"\"\"\n",
    "        texts = self.tokenize(text)\n",
    "        \n",
    "        categories = np.array(self.predict(text))\n",
    "        labels = np.array(labels)\n",
    "        acc = sum(categories == labels) / len(labels)\n",
    "            \n",
    "        return acc\n",
    "\n",
    "    def get_probs(self, text):\n",
    "        \"\"\"\n",
    "        Считает вероятности принадлежности текста (text) к каждой из категорий\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text : list of str | str\n",
    "            Входной текст описывается строкой, которая будет токенизирована по пробелу.\n",
    "            Если строка не токенизирована, то текст должен быть токенизирован.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        probs : list of float\n",
    "            Возвращает вероятности probs всех категорий для текста text\n",
    "            в порядке их следования в self.category_doc_counts.\n",
    "        \"\"\"\n",
    "        # Токенизируем текст, если это необходимо\n",
    "        text = self.tokenize(text)[0]\n",
    "            \n",
    "        probs = []\n",
    "        for cat in self.get_categories():\n",
    "            probs.append(self.get_category_prob(cat, text))\n",
    "\n",
    "        return probs\n",
    "\n",
    "    def get_category_prob(self, cat, text):\n",
    "        \"\"\"\n",
    "        Считает логарифм вероятности принадлежности сообщения text к категории cat.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        cat : str\n",
    "            Название категории.\n",
    "\n",
    "        text : list of str\n",
    "            Список из слов.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        log_prob : float\n",
    "            Возвращает логарифм вероятности категории cat для текста text.\n",
    "        \"\"\"\n",
    "        log_prob = np.log(self.category_priors[cat]) \\\n",
    "            + sum(list(map(lambda word: np.log(self.get_weighted_feature_prob(cat, word)), text)))\n",
    "\n",
    "        return log_prob\n",
    "\n",
    "    def get_weighted_feature_prob(self, cat, feature):\n",
    "        \"\"\"\n",
    "        Вычисляет взвешенную вероятность P(Слово|Категория).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        \n",
    "        cat : str\n",
    "            Название категории.\n",
    "\n",
    "        feature : str\n",
    "            Слово из текста.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        prob : float\n",
    "            Возвращает взвешенную вероятность слова feature при условии категории cat.\n",
    "        \"\"\"\n",
    "        if feature in self.feature_counts:\n",
    "            prob = (self.weight \\\n",
    "                    * (self.feature_counts[feature] / self.feature_count \\\n",
    "                    + (self.feature_category_counts[cat][feature] \\\n",
    "                       / self.feature_category_count[cat]))) \\\n",
    "                / (self.weight + 1)\n",
    "        else:\n",
    "            return 0.5\n",
    "        \n",
    "        return prob\n",
    "\n",
    "    def get_categories(self):\n",
    "        \"\"\"\n",
    "        Возвращает список названий всех категорий.\n",
    "        Returns\n",
    "        -------\n",
    "        cat_list : list of str\n",
    "        \"\"\"\n",
    "        cat_list = list(self.category_doc_counts.keys())\n",
    "        return cat_list\n",
    "    \n",
    "    def tokenize(self, text):\n",
    "        \"\"\"\n",
    "        Токенизирует тексты, если это необходимо\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text : list of list of str | list of str | str\n",
    "            Входной текст описывается строкой, которая будет токенизирована по пробелу.\n",
    "            Если строка не токенизирована, то текст должен быть токенизирован.\n",
    "            Может быть передано несколько сообщений, которые будут токенезированы, если необходимо.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        texts : list of list of str | list of srt\n",
    "            Возвращает токенизированные тексты.\n",
    "        \"\"\"\n",
    "        if isinstance(text, str):\n",
    "            texts = [ text.split() ]\n",
    "        elif isinstance(text[0], str):\n",
    "            if np.any(list(map(lambda element: \" \" in element, text))):\n",
    "                texts = list(map(lambda document: document.split(), text))\n",
    "            else:\n",
    "                texts = [ text ]\n",
    "        else:\n",
    "            texts = text\n",
    "            \n",
    "        return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сравните вашу реализацию и реализацию из библиотеки nltk\n",
    "\n",
    "Для использования классификатора из библиотеки не забудьте предподготовить данные. Для подсчета точности этого классификатора можете использовать accuracy_score из метрик sklearn. Для подсчета точности предсказаний вашего классификатора используйте функцию score, которую вы опишете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предобработка данных для классификатора nltk, если требуется\n",
    "class NLTKData:\n",
    "    def __init__(self, vocabulary, text):\n",
    "        self.vocabulary = vocabulary\n",
    "        self.text = text\n",
    "        self.words = set(text)\n",
    "    \n",
    "    def items(self):\n",
    "        items = []\n",
    "        for word in self.vocabulary:\n",
    "            items.append((word, word in self.words))\n",
    "        return items\n",
    "    \n",
    "    def keys(self):\n",
    "        return list(self.vocabulary)\n",
    "    \n",
    "    def copy(self):\n",
    "        return NLTKData(self.vocabulary, self.text)\n",
    "        \n",
    "class NLTKCreator:\n",
    "    def __init__(self, texts):\n",
    "        self.vocabulary = set()\n",
    "        for text in texts:\n",
    "            self.vocabulary.update(text)\n",
    "    \n",
    "    def create(self, text):\n",
    "        return NLTKData(self.vocabulary, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tokens = list(map(lambda doc: doc.lower().split(), X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_creator = NLTKCreator(X_tokens)\n",
    "X_nltk = np.array(list(map(nltk_creator.create, X_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1695d75f8434c5eb5ea4c9e87a540e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(NLTK) [Fold 0]: 0.9517241379310345\n",
      "(NLTK) [Fold 1]: 0.9517241379310345\n",
      "(NLTK) [Fold 2]: 0.9655172413793104\n",
      "(NLTK) [Fold 3]: 0.9653979238754326\n",
      "(NLTK) [Fold 4]: 0.9584775086505191\n",
      "(NLTK) [Fold 5]: 0.9619377162629758\n",
      "(NLTK) [Fold 6]: 0.9480968858131488\n",
      "(NLTK) [Fold 7]: 0.916955017301038\n",
      "(NLTK) [Fold 8]: 0.9619377162629758\n",
      "(NLTK) [Fold 9]: 0.9653979238754326\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Используйте процедуру KFold для проверки качества классификаторов\n",
    "kf = KFold(len(y), n_folds=10, shuffle=True, random_state=24)\n",
    "\n",
    "nltk_accuracy = []\n",
    "for k, (train_index, test_index) in tqdm_notebook(enumerate(kf)):\n",
    "    nb = NaiveBayesClassifier.train(zip(X_nltk[train_index], y[train_index]))\n",
    "    \n",
    "    cat = list(map(nb.classify, X_nltk[test_index]))\n",
    "    nltk_accuracy.append(accuracy_score(cat, y[test_index]))\n",
    "    print(\"(NLTK) [Fold {}]: {}\".format(k, nltk_accuracy[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b5d41046bc240b4987b0bf29da8e02c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(NaiveBayes) [Fold 0]: 0.9448275862068966\n",
      "(NaiveBayes) [Fold 1]: 0.9344827586206896\n",
      "(NaiveBayes) [Fold 2]: 0.9517241379310345\n",
      "(NaiveBayes) [Fold 3]: 0.972318339100346\n",
      "(NaiveBayes) [Fold 4]: 0.9411764705882353\n",
      "(NaiveBayes) [Fold 5]: 0.9411764705882353\n",
      "(NaiveBayes) [Fold 6]: 0.9584775086505191\n",
      "(NaiveBayes) [Fold 7]: 0.9757785467128027\n",
      "(NaiveBayes) [Fold 8]: 0.972318339100346\n",
      "(NaiveBayes) [Fold 9]: 0.9515570934256056\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Используйте процедуру KFold для проверки качества классификаторов\n",
    "kf = KFold(len(y), n_folds=10, shuffle=True, random_state=24)\n",
    "\n",
    "naive_accuracy = []\n",
    "for k, (train_index, test_index) in tqdm_notebook(enumerate(kf)):    \n",
    "    nb = NaiveBayes()\n",
    "    nb.fit(X[train_index], y[train_index])\n",
    "    naive_accuracy.append(nb.score(X[test_index], y[test_index]))\n",
    "    print(\"(NaiveBayes) [Fold {}]: {}\".format(k, naive_accuracy[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Постройте графики размаха для двух классификаторов на одной фигуре.\n",
    "\n",
    "Рекомендуется использовать встроенные функции построения графиков в pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_accuracy = [0.9517241379310345, 0.9517241379310345, 0.9655172413793104,\n",
    "                 0.9653979238754326, 0.9584775086505191, 0.9619377162629758,\n",
    "                 0.9480968858131488, 0.916955017301038, 0.9619377162629758, \n",
    "                 0.9653979238754326]\n",
    "\n",
    "naive_accuracy = [0.9448275862068966, 0.9344827586206896, 0.9517241379310345,\n",
    "                  0.972318339100346, 0.9411764705882353, 0.9411764705882353, \n",
    "                  0.9584775086505191, 0.9757785467128027, 0.972318339100346, \n",
    "                  0.9515570934256056]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11139c588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "bp = plt.boxplot([nltk_accuracy, naive_accuracy], patch_artist=True)\n",
    "\n",
    "## change outline color, fill color and linewidth of the boxes\n",
    "for box in bp['boxes']:\n",
    "    # change outline color\n",
    "    box.set( color='#7570b3', linewidth=2)\n",
    "    # change fill color\n",
    "    box.set( facecolor = '#1b9e77' )\n",
    "\n",
    "## change color and linewidth of the whiskers\n",
    "for whisker in bp['whiskers']:\n",
    "    whisker.set(color='#7570b3', linewidth=2)\n",
    "\n",
    "## change color and linewidth of the caps\n",
    "for cap in bp['caps']:\n",
    "    cap.set(color='#7570b3', linewidth=2)\n",
    "\n",
    "## change color and linewidth of the medians\n",
    "for median in bp['medians']:\n",
    "    median.set(color='#b2df8a', linewidth=2)\n",
    "\n",
    "## change the style of fliers and their fill\n",
    "for flier in bp['fliers']:\n",
    "    flier.set(marker='o', color='#e7298a', alpha=0.5)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
